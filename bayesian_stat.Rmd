---
title: "Bayesian Statistics"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Bayesian Statistics

## Probability

* Complement : P(Ac) = 1−P(A)
* P(A union B) = P(A) + P(B) − P(A inter B)
* If A mutually exclusive : p(union Ai) = sum(p(Ai))
* Odds = p(A) / (1-p(A))
* Expectation : E(X)=sum(xi*p(X=xi))
* Classical framework : outcomes that are equally likely have equal probabilities => works really well when we have equally likely outcomes or well-defined equally likely outcomes. That's very difficult to apply in any of these other cases.
* Frequentist framework : requires us to have a hypothetical infinite sequence of events, and then we look at the relevant frequency, in that hypothetical infinite sequence => works great when we can define a hypothetical infinite sequence. But then we can ask other questions, and they become more complicated under this approach.For example, what is the probability that it rains tomorrow? In this case, we need to think about hypothetical infinite sequence of tomorrow, and see what fraction of these infinite possible tomorrows have rain, which is a bit strange to think about.
* Bayesian probability : your probability represents your own perspective, it's your measure of uncertainty, and it takes into account what you know about a particular problem => inherently a subjective approach to probability, but it can work well in a mathematically rigorous foundation, and it leads to much more intuitive results in many cases than the Frequentist approach

## Bayes’ theorem

### Conditional probability

* p(A | B) = p(A inter B) / p(B)
* Independance : 
    + p(A | B) = p(A) 
    + p(A inter B) = p(A)*p(B)
* If p(A | B) <> p(A) => A and B not independant ! 

### Bayes’ theorem

* Bayes' Theorem is used to reverse the direction of conditioning. Suppose we want to ask what's the P(A|B) but we know it in terms of P(B|A). So we can write the P(A|B) = P(B|A) P(A) / P(B) = P(B|A) P(A) / P(B|A) P(A) + P(B| not A) P(not A) This does work out back to be the same as the P(A and B) / P(B)
* Used if not all info to compute directly p(A inter B) / p(B)
* Results sometimes surprising, e.g. rare diseases => even with accurate tests, false positives > true positives
* Example :
    + p(+|HIV) = 0.977
    + p(-|noHIV) = 0.926
    + p(HIV) = 0.0026
* This obviously has important policy implications for things like mandatory testing. It makes much more sense to test in a sub population where the prevalence of HIV is higher, rather than in a general population where it's quite rare
* To conclude, Bayes' Theorem is an important part of our approach to Bayesian statistics. We can use it to update our information. We start with prior beliefs, we'll collect data, we'll then condition on the data to lead to our posterior beliefs. Bayes' Theorem is the coherent way to do this updating

```{r hiv, eval=F}
p_pos_HIV<- 0.977
p_neg_noHIV<-0.926
p_HIV<- 0.0026

p_HIV_pos<-(p_pos_HIV*p_HIV)/(p_pos_HIV*p_HIV+(1-p_neg_noHIV)*(1-p_HIV))
print(proba)
p_HIV_pos

```

## Review of distributions

### Bernoulli and binomial distributions

* Bernoulli distribution : used when we have two possible outcomes, such as flipping a coin
* The generalization of the Bernoulli when we have n repeated trials is a binomial.Binomial is just the sum of the N independent Bernoullis. We can say X follows a binomial distribution with parameters n and p

### Uniform distribution

* The PDF is sort of proportional to the probability that the random variable will take a particular value. In differential calculus sense because it can take an infinite number of possible values. The key idea is that if you integrate the PDF over an interval, it gives you the probability that the random variable would be in that interval
* uniform (0,1) : f(x) = I{0<=x<=1} => proba = integrating f(x)
* uniform (a,b) : f(x) = 1/(b-a) * I{a<=x<=b} 

### Exponential and normal distributions

* Exponential distr : events that are occurring at a particular rate, and the exponential is the waiting time in between events. For example, you're waiting for a bus. The bus comes once every ten minutes. And then, the exponential is your waiting time. This is particularly true for events coming from a poisson process

```{r distrib, eval=F}
## Quizz 2
# titanic
s<-203+118+178+212
d<-122+167+528+673

(203+122)/(s+d)
s/(s+d)
(203/(s+d))/((203+122)/(s+d))

# marbles
pblue<-1/3*3/5+1/3*1/6+1/3*0
3/5*1/3/pblue

pred<-1-pblue
1*1/3/pred

## Quizz 3
4*3*2*1/(3*2*1)
0.2*1+0.2*2+0.1*3
(1-0.2)**3

## Quizz honor
lambda<-3
x<-0.3
1-(1-exp(-lambda*x))
34+2*(-5-1*(-2))
```


# Statistical Inference

## Frequentist inference

* Under the frequentist paradigm, you view the data as a random sample from some larger, potentially hypothetical population. We can then make probability statements i.e, long-run frequency statements based on this larger population

### Confidence intervals

* Under the frequentist paradigm, what this means is we have to think back to our infinite hypothetical sequence of events. So if we were to repeat this trial an infinite number of times, or an arbitrary large number of times.
* Each time we create a confidence interval in this way based on the data we observe. Than on average 95% of the intervals we make will contain the true value of p
* What's the probability that this interval contains a true p? Well, we don't know for this particular interval. But under the frequentist paradigm, we're assuming that there is a fixed right answer for p. Either p is in that interval or it's not in that interval. And so technically, from a frequentist perspective, the probability that p is in this interval is either 0 or 1. This is not a particularly satisfying explanation. In the other hand when we get to the Bayesian approach we will be able to compute an interval and actually say there is probably a p is in this interval is 95% based on a random interpretation of an unknown parameter

### Likelihood function, max likelihood

* The likelihood function is this density function thought of as a function of theta. This is not a probability distribution anymore, but it is still a function for theta.One way to estimate theta is that we choose the theta that gives us the largest value of the likelihood. It makes the data the most likely to occur for the particular data we observed.This is referred to as the maximum likelihood estimate, or MLE, maximum likelihood estimate.
* In practice, it's usually easier to maximize the natural logarithm of the likelihood, referred to as the log likelihood.

### Computing the MLE

* Maximum likelihood estimators have many desirable mathematical properties. They're unbiased, they're consistent, and they're invariant.
* In general, under certain regularity conditions, we can say that the MLE is approximately normally distributed with mean at the true value of theta and variance one over the Fisher information the value at theta hat. We'll return to the Fisher information later. The Fisher information is a measure of how much information about theta is in each data point.

```{r freq_inf, eval=F}
## Quizz 4
theta<-47/100
n<-100
up<-theta+1.96*(theta*(1-theta)/n)**(1/2)
low<-theta-1.96*(theta*(1-theta)/n)**(1/2)
5/(2+2.5+4.1+1.8+4.0)
mean(c(−1.2,0.5,0.8,−0.3))

```
```{r likelihood_fct, echo=TRUE}
## fonction likelihood (loi binomiale)
y<-72
n<-400
lik_fct<-function(n,y,theta){return(theta^y*(1-theta)^(n-y))}
theta<-seq(from=0.01, to=0.99, by=0.01)
plot(theta, lik_fct(n,y, theta))
abline(v=y/n)


```

## Bayesian inference

### Inference examples : frequentist, bayesian

* Maximum likelihood estimate : given the data, it is most likely that the coin is fair.
* Question "how sure are you?" not easily answered in the frequentist paradigm. Another question is that we might like to know what is the probability that theta equals fair, given, we observed two heads
* **Frequentist paradigm** : the coin is a physical quantity. It's a fixed coin, and therefore it has a fixed probability of coming up heads. It either is the fair coin, or it's the loaded coin (probability is either 0 or 1) => not a particularly satisfying answer. 
* **Bayesian approache** : allows you to easily incorporate prior information, when you know something in advance of the looking at the data $f(\theta|x)= \frac{f(x|\theta)f(\theta)}{\sum_{\theta} f(x|\theta)f(\theta)}$ where ${\sum_{\theta} f(x|\theta)f(\theta)}=f(x)$ = normalizing constant, so that when we divide by this, we'll get answers that add up to one
* **Bayesian approach is inherently subjective** but done in a mathematically vigorous framework, and it's all mathematically consistent and coherent.

```{r quizz_5.1-5.2, echo=TRUE}

# conservative vs liberal
# ! succès = répondre non !
0.5*dbinom(x = 0, size = 5, prob = 0.8)/(0.5*dbinom(x = 0, size = 5, prob = 0.8)+0.5*dbinom(x = 0, size = 5, prob = 0.3))
0.5*dbinom(x = 0, size = 5, prob = 0.3)/(0.5*dbinom(x = 0, size = 5, prob = 0.8)+0.5*dbinom(x = 0, size = 5, prob = 0.3))

# coin
postprob<-function(t=c(1/2, 7/10, 3/10), prior=c(0.4, 0.3, 0.3),
                   size=4, n=2){
    
         tmp<-vector()
         for (i in 1:length(t)){
             tmp[i]<-prior[i]*dbinom(x = n, size = size, prob = t[i])
            }
         return(tmp)
     }

a<-postprob(n=2)
a/sum(a)

```

### Continuous version of Bayesian theorem

* Continuous version : $f(\theta|x)= \frac{f(x|\theta)f(\theta)}{\int_{\theta} f(x|\theta)f(\theta)d\theta}\propto f(x|\theta)f(\theta)$, proportionnal to the likelihood * prior (normalizing constant independant of $\theta$)

### Posterior intervals

* HPD, Highest Posterior Density  = the shortest possible interval that contains the given probability, in this case a 95% probability
* The posterior distribution describes our understanding of our uncertainty combining our prior beliefs and the data
* In this case, we can legitimately say, the posterior probability Theta is bigger than .05, is .9975. Or, we believe there's a 95% probability the Theta is in between .158 and .987. Frequentest can't do this. Bayesians represent uncertainty with probabilities. So the coin itself is a physical quantity. It may have a particular value for Theta. It may be fixed, but because we don't know what that value is, we represent our uncertainty about that value with a distribution

```{r eval=F, echo=F}

qnorm(0.975)
y<-10
n<-25
lik_fct<-function(n,y,theta){return(theta^y*(1-theta)^(n-y))}
theta<-seq(from=0.01, to=0.99, by=0.01)
plot(theta, lik_fct(n,y, theta))
abline(v=y/n)

(y/n)/(1-y/n)

0.6/(1-0.6)

0.6-(1-0.6)*0.6/(1-0.6)

new_p<-0.7*0.6/(0.7*0.6+0.5*0.4)

new_p/(1-new_p)

factorial(5)

```


# Priors and Models for Discrete Data

## Priors

### Priors and posterior predictive distributions

* Our prior needs to represent our personal perspective, our beliefs, and our uncertainties. Theoretically we're defining a cumulative distribution function for the parameter. So in particular we're defining probability that theta is lesser or equal to some value of c for all possible c on the real line.
* Generally if one has enough data, the information in the data will overwhelm the invasion of prior. And so it, prior is not particularly important in terms of what you get for the posterior. Any reasonable choice of prior will lead to approximately the same posterior. However, there are some things that can go wrong
* **So in the bayesian context, events with prior probability of zero have posterior probability of zero, events with prior probability of one, have posterior probability of one regardless of the data**. Thus a good bayesian will not assign probability of zero or one to any event that has already occurred or already known not to occur
* Prior predictive intervals are useful because they reveal the consequences of the prior at the data (observation) level. The prior predictive distribution is $f(y) = \int{f(y|\theta)f(\theta)d\theta} = \int{f(y, \theta)d\theta}$

### Prior predictive : binomial example

* if we start with a uniform prior, we then end up with a discrete uniform predictive density for X. If all possible coins or all possible probabilities are equally likely, then all possible X outcomes are equally likely

### Posterior predictive distribution

* What about after we've observed data? What's our posterior predictive distribution?
* Prior vs posterior predictive distribution : they are the same procedure, except in one case you use the prior for $\theta$ and in the other case you use the posterior for $\theta$ : $\theta|y$
* The posterior predictive distribution is $f(y2|y1) = \int{f(y2|\theta,y1)f(\theta|y1)d\theta}$. If y2 and y1 independant :  $f(y2|y1) = \int{f(y2|\theta)f(\theta|y1)d\theta}$.

## Bernoulli/binomial data

* When we use a uniform prior for a Bernoulli likelihood ($\theta$), we get a beta posterior. Thus we see the posterior for $\theta|y$ follows a beta distribution with parameters $\sum{y_{i}}+1$, and $n-\sum{y_{i}}+1$. NB : prior = $f(\theta)$, posterior = $f(\theta|y)$  
* the uniform distribution, is a beta one one. Any beta distribution, is conjugate for the Bernoulli distribution. Any beta prior, will give a beta posterior. If prior follows a beta distribution with parameters $\alpha$ and $\beta$, posterior follows beta distribution with parameters $\sum{y_{i}}+\alpha$, and $n-\sum{y_{i}}+\beta$
* This whole concept of starting with the beta prior and getting a beta posterior is a really convenient one. A family of distributions is referred to as conjugate if when you use a member of that family as a prior, you get another member of that family as your posterior. The beta distribution is conjugate for the Bernoulli distribution. It's also conjugate for the binomial distribution
* We often use conjugate priors because they make life much more simpler. If the family is flexible enough, then you can find a member of that family that closely enough represents your beliefs. We can represent this model as a hierarchy.

### Posterior mean, effective sample size

* Prior : effective sample size = $\alpha+\beta$, mean= $\frac{\alpha}{\alpha+\beta}$
* Posterior mean = $\frac{\sum{y_{i}}+\alpha}{n-\sum{y_{i}}+\beta+\sum{y_{i}}+\alpha}=\frac{\alpha+\beta}{\alpha+\beta+n}\cdot\frac{\alpha}{\alpha+\beta}+\frac{n}{\alpha+\beta+n}\cdot\frac{\sum{y_{i}}}{n}$ = prior_wgt * prior_mean + data_wgt*data_mean => which n so that prior not too much weight !
* Sequential analysis : use previous posterior as new prior ! E.g. medical device testing => small samples after each adaptation

```{r echo=F, results="hide"}

# Suppose we are giving two students a multiple-choice exam with 40 questions, 
# where each question has four choices. We don't know how much the students
# have studied for this exam, but we think that they will do better than just
# guessing randomly. 
# 1) What are the parameters of interest?
# 2) What is our likelihood?
# 3) What prior should we use?
# 4) What is the prior probability P(theta>.25)? P(theta>.5)? P(theta>.8)?
# 5) Suppose the first student gets 33 questions right. What is the posterior
#    distribution for theta1? P(theta1>.25)? P(theta1>.5)? P(theta1>.8)?
#    What is a 95% posterior credible interval for theta1?
# 6) Suppose the second student gets 24 questions right. What is the posterior
#    distribution for theta2? P(theta2>.25)? P(theta2>.5)? P(theta2>.8)?
#    What is a 95% posterior credible interval for theta2?
# 7) What is the posterior probability that theta1>theta2, i.e., that the 
#    first student has a better chance of getting a question right than
#    the second student?

############
# Solutions:

# 1) Parameters of interest are theta1=true probability the first student
#    will answer a question correctly, and theta2=true probability the second
#    student will answer a question correctly.

# 2) Likelihood is Binomial(40, theta), if we assume that each question is 
#    independent and that the probability a student gets each question right 
#    is the same for all questions for that student.

# 3) The conjugate prior is a beta prior. Plot the density with dbeta.
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,1,1),type="l")
plot(theta,dbeta(theta,4,2),type="l")
plot(theta,dbeta(theta,8,4),type="l")

# 4) Find probabilities using the pbeta function.
1-pbeta(.25,8,4)
1-pbeta(.5,8,4)
1-pbeta(.8,8,4)

# 5) Posterior is Beta(8+33,4+40-33) = Beta(41,11)
41/(41+11)  # posterior mean
33/40       # MLE

lines(theta,dbeta(theta,41,11))

# plot posterior first to get the right scale on the y-axis
plot(theta,dbeta(theta,41,11),type="l")
lines(theta,dbeta(theta,8,4),lty=2)
# plot likelihood
lines(theta,dbinom(33,size=40,p=theta),lty=3)
# plot scaled likelihood
lines(theta,44*dbinom(33,size=40,p=theta),lty=3)

# posterior probabilities
1-pbeta(.25,41,11)
1-pbeta(.5,41,11)
1-pbeta(.8,41,11)

# equal-tailed 95% credible interval
qbeta(.025,41,11)
qbeta(.975,41,11)

# 6) Posterior is Beta(8+24,4+40-24) = Beta(32,20)
32/(32+20)  # posterior mean
24/40       # MLE

plot(theta,dbeta(theta,32,20),type="l")
lines(theta,dbeta(theta,8,4),lty=2)
lines(theta,44*dbinom(24,size=40,p=theta),lty=3)

1-pbeta(.25,32,20)
1-pbeta(.5,32,20)
1-pbeta(.8,32,20)

qbeta(.025,32,20)
qbeta(.975,32,20)

# 7) Estimate by simulation: draw 1,000 samples from each and see how often 
#    we observe theta1>theta2

theta1=rbeta(1000,41,11)
theta2=rbeta(1000,32,20)
mean(theta1>theta2)


# Note for other distributions:
# dgamma,pgamma,qgamma,rgamma
# dnorm,pnorm,qnorm,rnorm
```

```{r echo=F, results="hide"}
1/6
s<-dbeta(seq(0,1, by=0.05),1,5)
plot(s)
1/(4+1+5)
pbeta(0.5, 1, 5)
qbeta(0.975, 8, 16)
pbeta(0.35, 8, 16)
pbeta(0.35, 8, 21)


```

## Poisson data

* If y follows poisson distribution, likelihood sample y=y1,..yi,..= $f(y| \lambda)=\frac{\lambda^{\sum{y_{i}}}e^{-n\lambda}}{\prod_{i}y_{i}!}$, for $\lambda > 0$
* prior $f(\lambda)$ = gamma distribution $\Gamma(\alpha, \beta)$
* posterior = gamma distribution $\Gamma(\alpha+\sum{y_{i}}, \beta+n)$
* prior mean= $\frac{\alpha}{\beta}$
* posterior mean= $\frac{\beta}{\beta+n}\cdot\frac{\alpha}{\beta}+\frac{n}{\beta+n}\cdot\frac{\sum{y_{i}}}{n}$
* how to define $\alpha$ and $\beta$ ?
    + strategy 1 : idea on the prior mean (how many counts per period) => $\frac{\alpha}{\beta}$ **AND**
        + idea on std of prior mean => $\frac{\sqrt\alpha}{\beta}$ **OR**
        + effective sample size = $\beta$
    + strategy 2 : vague prior $\Gamma(\epsilon, \epsilon)$ with $\epsilon$ small
        
 ```{r echo=F, results="hide"}

mean<-8
beta<-1
beta*mean

9+12+10+15+13

plot(dgamma(1:20, 67,6), type="l")
lines(dgamma(1:20, 8,1))

67/6

qgamma(0.05, 67, 6)

plot(dbeta(seq(0,1,length=20),2,2))

```      

